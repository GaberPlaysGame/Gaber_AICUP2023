{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\gaberil0903\\anaconda3\\lib\\site-packages (4.3.0)\n",
      "Collecting gensim\n",
      "  Downloading gensim-4.3.1-cp310-cp310-win_amd64.whl (24.0 MB)\n",
      "     ---------------------------------------- 0.0/24.0 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/24.0 MB 1.3 MB/s eta 0:00:19\n",
      "     ---------------------------------------- 0.1/24.0 MB 1.3 MB/s eta 0:00:19\n",
      "     ---------------------------------------- 0.2/24.0 MB 1.6 MB/s eta 0:00:16\n",
      "      --------------------------------------- 0.3/24.0 MB 1.8 MB/s eta 0:00:14\n",
      "      --------------------------------------- 0.4/24.0 MB 1.8 MB/s eta 0:00:14\n",
      "     - -------------------------------------- 0.7/24.0 MB 2.4 MB/s eta 0:00:10\n",
      "     - -------------------------------------- 0.9/24.0 MB 3.0 MB/s eta 0:00:08\n",
      "     - -------------------------------------- 0.9/24.0 MB 3.0 MB/s eta 0:00:08\n",
      "     - -------------------------------------- 0.9/24.0 MB 3.0 MB/s eta 0:00:08\n",
      "     --- ------------------------------------ 1.9/24.0 MB 4.1 MB/s eta 0:00:06\n",
      "     --- ------------------------------------ 2.1/24.0 MB 4.0 MB/s eta 0:00:06\n",
      "     --- ------------------------------------ 2.2/24.0 MB 3.8 MB/s eta 0:00:06\n",
      "     ---- ----------------------------------- 2.5/24.0 MB 4.1 MB/s eta 0:00:06\n",
      "     ---- ----------------------------------- 2.9/24.0 MB 4.4 MB/s eta 0:00:05\n",
      "     ----- ---------------------------------- 3.2/24.0 MB 4.5 MB/s eta 0:00:05\n",
      "     ----- ---------------------------------- 3.4/24.0 MB 4.7 MB/s eta 0:00:05\n",
      "     ------ --------------------------------- 3.8/24.0 MB 4.8 MB/s eta 0:00:05\n",
      "     ------ --------------------------------- 4.1/24.0 MB 4.8 MB/s eta 0:00:05\n",
      "     ------- -------------------------------- 4.3/24.0 MB 4.9 MB/s eta 0:00:05\n",
      "     ------- -------------------------------- 4.6/24.0 MB 4.9 MB/s eta 0:00:04\n",
      "     -------- ------------------------------- 4.9/24.0 MB 4.9 MB/s eta 0:00:04\n",
      "     -------- ------------------------------- 5.1/24.0 MB 4.9 MB/s eta 0:00:04\n",
      "     -------- ------------------------------- 5.4/24.0 MB 5.0 MB/s eta 0:00:04\n",
      "     --------- ------------------------------ 5.6/24.0 MB 5.0 MB/s eta 0:00:04\n",
      "     --------- ------------------------------ 5.9/24.0 MB 5.0 MB/s eta 0:00:04\n",
      "     ---------- ----------------------------- 6.2/24.0 MB 5.1 MB/s eta 0:00:04\n",
      "     ---------- ----------------------------- 6.5/24.0 MB 5.1 MB/s eta 0:00:04\n",
      "     ----------- ---------------------------- 6.7/24.0 MB 5.1 MB/s eta 0:00:04\n",
      "     ----------- ---------------------------- 7.0/24.0 MB 5.1 MB/s eta 0:00:04\n",
      "     ------------ --------------------------- 7.3/24.0 MB 5.2 MB/s eta 0:00:04\n",
      "     ------------ --------------------------- 7.5/24.0 MB 5.2 MB/s eta 0:00:04\n",
      "     ------------- -------------------------- 7.8/24.0 MB 5.2 MB/s eta 0:00:04\n",
      "     ------------- -------------------------- 8.1/24.0 MB 5.2 MB/s eta 0:00:04\n",
      "     -------------- ------------------------- 8.4/24.0 MB 5.3 MB/s eta 0:00:03\n",
      "     -------------- ------------------------- 8.7/24.0 MB 5.3 MB/s eta 0:00:03\n",
      "     -------------- ------------------------- 9.0/24.0 MB 5.3 MB/s eta 0:00:03\n",
      "     --------------- ------------------------ 9.2/24.0 MB 5.3 MB/s eta 0:00:03\n",
      "     --------------- ------------------------ 9.5/24.0 MB 5.3 MB/s eta 0:00:03\n",
      "     ---------------- ----------------------- 9.8/24.0 MB 5.3 MB/s eta 0:00:03\n",
      "     ---------------- ----------------------- 10.1/24.0 MB 5.4 MB/s eta 0:00:03\n",
      "     ----------------- ---------------------- 10.4/24.0 MB 5.6 MB/s eta 0:00:03\n",
      "     ----------------- ---------------------- 10.6/24.0 MB 5.9 MB/s eta 0:00:03\n",
      "     ------------------ --------------------- 10.9/24.0 MB 5.9 MB/s eta 0:00:03\n",
      "     ------------------ --------------------- 11.2/24.0 MB 6.4 MB/s eta 0:00:03\n",
      "     ------------------- -------------------- 11.5/24.0 MB 6.2 MB/s eta 0:00:03\n",
      "     ------------------- -------------------- 11.8/24.0 MB 6.1 MB/s eta 0:00:03\n",
      "     -------------------- ------------------- 12.1/24.0 MB 5.9 MB/s eta 0:00:03\n",
      "     -------------------- ------------------- 12.4/24.0 MB 6.0 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 12.7/24.0 MB 6.0 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 13.0/24.0 MB 6.0 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 13.3/24.0 MB 6.0 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 13.5/24.0 MB 6.0 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 13.9/24.0 MB 6.0 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 14.1/24.0 MB 6.0 MB/s eta 0:00:02\n",
      "     ------------------------ --------------- 14.4/24.0 MB 6.0 MB/s eta 0:00:02\n",
      "     ------------------------ --------------- 14.7/24.0 MB 6.0 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 15.1/24.0 MB 6.0 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 15.3/24.0 MB 6.1 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 15.6/24.0 MB 6.1 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 15.9/24.0 MB 6.1 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 16.3/24.0 MB 6.1 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 16.5/24.0 MB 6.1 MB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 16.9/24.0 MB 6.2 MB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 17.1/24.0 MB 6.2 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 17.4/24.0 MB 6.2 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 17.8/24.0 MB 6.2 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 18.1/24.0 MB 6.2 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 18.4/24.0 MB 6.2 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 18.7/24.0 MB 6.3 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 19.0/24.0 MB 6.3 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 19.3/24.0 MB 6.3 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 19.6/24.0 MB 6.3 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 19.9/24.0 MB 6.4 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 20.2/24.0 MB 6.4 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 20.5/24.0 MB 6.4 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 20.8/24.0 MB 6.4 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 21.1/24.0 MB 6.4 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 21.5/24.0 MB 6.4 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 21.8/24.0 MB 6.4 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 22.1/24.0 MB 6.4 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 22.4/24.0 MB 6.4 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 22.7/24.0 MB 6.5 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 23.0/24.0 MB 6.5 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 23.3/24.0 MB 6.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  23.7/24.0 MB 6.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  24.0/24.0 MB 6.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 24.0/24.0 MB 6.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\gaberil0903\\anaconda3\\lib\\site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\gaberil0903\\anaconda3\\lib\\site-packages (from gensim) (1.10.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\gaberil0903\\anaconda3\\lib\\site-packages (from gensim) (1.23.5)\n",
      "Installing collected packages: gensim\n",
      "  Attempting uninstall: gensim\n",
      "    Found existing installation: gensim 4.3.0\n",
      "    Uninstalling gensim-4.3.0:\n",
      "      Successfully uninstalled gensim-4.3.0\n",
      "Successfully installed gensim-4.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "from gensim.corpora import WikiCorpus"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 導入維基語庫並生成文字檔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import opencc\n",
    "CONVERTER_T2S = opencc.OpenCC(\"t2s.json\")\n",
    "CONVERTER_S2T = opencc.OpenCC(\"s2t.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_st_corrections(txt: str) -> str:\n",
    "    simplified = CONVERTER_T2S.convert(txt)\n",
    "\n",
    "    return CONVERTER_S2T.convert(simplified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_wiki_text():\n",
    "    doc_path = f\"models/zhwiki-20221220-pages-articles-multistream.xml.bz2\"\n",
    "\n",
    "    if not Path(doc_path).exists:\n",
    "        print(\"The file doesn't exist.\")\n",
    "        exit()\n",
    "\n",
    "    logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "    wiki_corpus = WikiCorpus(doc_path, dictionary={})\n",
    "    texts_num = 0\n",
    "\n",
    "    wiki_text_path = f\"data/wiki-text/wiki_texts.txt\"\n",
    "    with open(wiki_text_path,'w',encoding='utf-8') as output:\n",
    "        for text in wiki_corpus.get_texts():\n",
    "            line = ' '.join(text) + '\\n'\n",
    "            do_st_corrections(line)\n",
    "            output.write(line)\n",
    "            texts_num += 1\n",
    "            if texts_num % 10000 == 0:\n",
    "                logging.info(\"已處理 %d 篇文章\" % texts_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gaberil0903\\anaconda3\\lib\\site-packages\\gensim\\utils.py:1333: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected %s; aliasing chunkize to chunkize_serial\" % entity)\n",
      "2023-04-21 13:04:53,397 : WARNING : user terminated iteration over Wikipedia corpus after 0 documents with 0 positions (total 0 articles, 0 positions before pruning articles shorter than 50 words)\n"
     ]
    }
   ],
   "source": [
    "write_wiki_text()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "處理繁簡轉換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "\n",
    "def tokenize():\n",
    "    logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "    # jieba custom setting.\n",
    "    jieba.set_dictionary('data/jieba_dict/dict.txt.big')\n",
    "\n",
    "    # load stopwords set\n",
    "    stopword_set = set()\n",
    "    with open('data/jieba_dict/stopwords.txt','r', encoding='utf-8') as stopwords:\n",
    "        for stopword in stopwords:\n",
    "            stopword_set.add(stopword.strip('\\n'))\n",
    "\n",
    "    output = open('data/wiki-text/wiki_seg.txt', 'w', encoding='utf-8')\n",
    "    with open('data/wiki-text/wiki_texts.txt', 'r', encoding='utf-8') as content :\n",
    "        for texts_num, line in enumerate(content):\n",
    "            line = line.strip('\\n')\n",
    "            words = jieba.cut(line, cut_all=False)\n",
    "            for word in words:\n",
    "                if word not in stopword_set:\n",
    "                    output.write(word + ' ')\n",
    "            output.write('\\n')\n",
    "\n",
    "            if (texts_num + 1) % 10000 == 0:\n",
    "                logging.info(\"已完成前 %d 行的斷詞\" % (texts_num + 1))\n",
    "    output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from d:\\VSCodeProject\\NCKU-AICUP2023-baseline\\data\\jieba_dict\\dict.txt.big ...\n",
      "2023-04-20 16:12:47,702 : DEBUG : Building prefix dict from d:\\VSCodeProject\\NCKU-AICUP2023-baseline\\data\\jieba_dict\\dict.txt.big ...\n",
      "Dumping model to file cache C:\\Users\\GABERI~1\\AppData\\Local\\Temp\\jieba.u155ec321d2357b8e7de4a678a68eea60.cache\n",
      "2023-04-20 16:12:48,634 : DEBUG : Dumping model to file cache C:\\Users\\GABERI~1\\AppData\\Local\\Temp\\jieba.u155ec321d2357b8e7de4a678a68eea60.cache\n",
      "Loading model cost 1.002 seconds.\n",
      "2023-04-20 16:12:48,705 : DEBUG : Loading model cost 1.002 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "2023-04-20 16:12:48,706 : DEBUG : Prefix dict has been built successfully.\n",
      "2023-04-20 16:14:38,197 : INFO : 已完成前 10000 行的斷詞\n",
      "2023-04-20 16:16:02,797 : INFO : 已完成前 20000 行的斷詞\n",
      "2023-04-20 16:17:12,808 : INFO : 已完成前 30000 行的斷詞\n",
      "2023-04-20 16:18:26,374 : INFO : 已完成前 40000 行的斷詞\n",
      "2023-04-20 16:19:30,858 : INFO : 已完成前 50000 行的斷詞\n",
      "2023-04-20 16:20:34,025 : INFO : 已完成前 60000 行的斷詞\n",
      "2023-04-20 16:21:34,945 : INFO : 已完成前 70000 行的斷詞\n",
      "2023-04-20 16:22:27,229 : INFO : 已完成前 80000 行的斷詞\n",
      "2023-04-20 16:23:19,848 : INFO : 已完成前 90000 行的斷詞\n",
      "2023-04-20 16:24:17,194 : INFO : 已完成前 100000 行的斷詞\n",
      "2023-04-20 16:25:09,927 : INFO : 已完成前 110000 行的斷詞\n",
      "2023-04-20 16:26:07,341 : INFO : 已完成前 120000 行的斷詞\n",
      "2023-04-20 16:26:53,086 : INFO : 已完成前 130000 行的斷詞\n",
      "2023-04-20 16:27:57,670 : INFO : 已完成前 140000 行的斷詞\n",
      "2023-04-20 16:28:53,016 : INFO : 已完成前 150000 行的斷詞\n",
      "2023-04-20 16:29:50,304 : INFO : 已完成前 160000 行的斷詞\n",
      "2023-04-20 16:30:43,173 : INFO : 已完成前 170000 行的斷詞\n",
      "2023-04-20 16:31:37,816 : INFO : 已完成前 180000 行的斷詞\n",
      "2023-04-20 16:32:30,073 : INFO : 已完成前 190000 行的斷詞\n",
      "2023-04-20 16:33:17,942 : INFO : 已完成前 200000 行的斷詞\n",
      "2023-04-20 16:34:07,662 : INFO : 已完成前 210000 行的斷詞\n",
      "2023-04-20 16:35:04,176 : INFO : 已完成前 220000 行的斷詞\n",
      "2023-04-20 16:35:54,071 : INFO : 已完成前 230000 行的斷詞\n",
      "2023-04-20 16:36:48,886 : INFO : 已完成前 240000 行的斷詞\n",
      "2023-04-20 16:37:42,289 : INFO : 已完成前 250000 行的斷詞\n",
      "2023-04-20 16:38:35,383 : INFO : 已完成前 260000 行的斷詞\n",
      "2023-04-20 16:39:32,364 : INFO : 已完成前 270000 行的斷詞\n",
      "2023-04-20 16:40:29,429 : INFO : 已完成前 280000 行的斷詞\n",
      "2023-04-20 16:41:24,388 : INFO : 已完成前 290000 行的斷詞\n",
      "2023-04-20 16:42:12,472 : INFO : 已完成前 300000 行的斷詞\n",
      "2023-04-20 16:42:56,777 : INFO : 已完成前 310000 行的斷詞\n",
      "2023-04-20 16:43:42,275 : INFO : 已完成前 320000 行的斷詞\n",
      "2023-04-20 16:44:27,047 : INFO : 已完成前 330000 行的斷詞\n",
      "2023-04-20 16:45:18,755 : INFO : 已完成前 340000 行的斷詞\n",
      "2023-04-20 16:46:11,026 : INFO : 已完成前 350000 行的斷詞\n",
      "2023-04-20 16:47:05,369 : INFO : 已完成前 360000 行的斷詞\n",
      "2023-04-20 16:47:59,043 : INFO : 已完成前 370000 行的斷詞\n",
      "2023-04-20 16:48:52,812 : INFO : 已完成前 380000 行的斷詞\n",
      "2023-04-20 16:49:42,290 : INFO : 已完成前 390000 行的斷詞\n",
      "2023-04-20 16:50:29,290 : INFO : 已完成前 400000 行的斷詞\n",
      "2023-04-20 16:51:16,454 : INFO : 已完成前 410000 行的斷詞\n",
      "2023-04-20 16:51:59,125 : INFO : 已完成前 420000 行的斷詞\n",
      "2023-04-20 16:52:44,749 : INFO : 已完成前 430000 行的斷詞\n",
      "2023-04-20 16:53:27,434 : INFO : 已完成前 440000 行的斷詞\n"
     ]
    }
   ],
   "source": [
    "tokenize()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "訓練詞向量 (要微調)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "\n",
    "def w2v():\n",
    "    w2v_model_path = \"models/w2v.zh.250/word2vec.model\"\n",
    "    logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "    sentences = word2vec.LineSentence(\"data/wiki-text/wiki_seg.txt\")\n",
    "    model = word2vec.Word2Vec(sentences, vector_size=250)\n",
    "\n",
    "    #保存模型，供日後使用\n",
    "    model.save(w2v_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-21 13:08:24,187 : INFO : loading Word2Vec object from models/w2v.zh.250/word2vec.model\n",
      "2023-04-21 13:08:24,594 : INFO : loading wv recursively from models/w2v.zh.250/word2vec.model.wv.* with mmap=None\n",
      "2023-04-21 13:08:24,595 : INFO : loading vectors from models/w2v.zh.250/word2vec.model.wv.vectors.npy with mmap=None\n",
      "2023-04-21 13:08:25,026 : INFO : loading syn1neg from models/w2v.zh.250/word2vec.model.syn1neg.npy with mmap=None\n",
      "2023-04-21 13:08:25,509 : INFO : setting ignored attribute cum_table to None\n",
      "2023-04-21 13:08:32,348 : INFO : Word2Vec lifecycle event {'fname': 'models/w2v.zh.250/word2vec.model', 'datetime': '2023-04-21T13:08:32.348099', 'gensim': '4.3.1', 'python': '3.10.9 | packaged by Anaconda, Inc. | (main, Mar  8 2023, 10:42:25) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'loaded'}\n"
     ]
    }
   ],
   "source": [
    "w2v_model_path = \"models/w2v.zh.250/word2vec.model\"\n",
    "if Path(w2v_model_path).exists:\n",
    "    w2v_model = word2vec.Word2Vec.load(w2v_model_path)\n",
    "else:\n",
    "    w2v()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('蘇格蘭', 0.7412448525428772),\n",
       " ('愛爾蘭', 0.729009747505188),\n",
       " ('英格蘭', 0.6906564831733704),\n",
       " ('美國', 0.6804454922676086),\n",
       " ('法國', 0.6544962525367737),\n",
       " ('澳大利亞', 0.6538345813751221),\n",
       " ('倫敦', 0.6519836783409119),\n",
       " ('英國政府', 0.6437056660652161),\n",
       " ('北愛爾蘭', 0.6304891109466553),\n",
       " ('紐西蘭', 0.6292421221733093)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# w2v_model.wv.most_similar(['英國'])         # Most Similar\n",
    "# w2v_model.wv.similarity('英國', '法國')   # Similarity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 | packaged by Anaconda, Inc. | (main, Mar  8 2023, 10:42:25) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "58f38e4893e5afed24ba0416c084b8b56093319a21f96223eaba66586e962656"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
